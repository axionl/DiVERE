"""
GPUåŠ é€Ÿå™¨æ¨¡å— - è·¨å¹³å°GPUåŠ é€Ÿæ”¯æŒ
æ”¯æŒOpenCL, CUDA, Metalç­‰å¤šç§GPUè®¡ç®—åç«¯
"""

import numpy as np
from typing import Optional, Dict, Any, List, Tuple
import time
import platform
from abc import ABC, abstractmethod

# å¯¼å…¥debug logger
from ..utils.debug_logger import debug, info, warning, error

# GPUåº“å¯¼å…¥ï¼ˆå¯é€‰ï¼‰
try:
    import pyopencl as cl
    OPENCL_AVAILABLE = True
except ImportError:
    OPENCL_AVAILABLE = False

try:
    import cupy as cp
    CUDA_AVAILABLE = True
except ImportError:
    CUDA_AVAILABLE = False

try:
    import Metal
    import MetalPerformanceShaders as MPS
    import objc
    METAL_AVAILABLE = True
except ImportError:
    METAL_AVAILABLE = False


class GPUComputeEngine(ABC):
    """GPUè®¡ç®—å¼•æ“æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def is_available(self) -> bool:
        """æ£€æŸ¥è®¡ç®—å¼•æ“æ˜¯å¦å¯ç”¨"""
        pass
    
    @abstractmethod
    def get_device_info(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        pass
    
    @abstractmethod
    def density_inversion_gpu(self, image: np.ndarray, gamma: float, 
                             dmax: float, pivot: float) -> np.ndarray:
        """GPUåŠ é€Ÿçš„å¯†åº¦åç›¸"""
        pass
    
    @abstractmethod
    def curve_processing_gpu(self, density_array: np.ndarray, 
                           lut: np.ndarray) -> np.ndarray:
        """GPUåŠ é€Ÿçš„æ›²çº¿å¤„ç†"""
        pass


class OpenCLEngine(GPUComputeEngine):
    """OpenCLè®¡ç®—å¼•æ“ - è·¨å¹³å°æ”¯æŒ"""
    
    def __init__(self):
        self.context = None
        self.queue = None
        self.device = None
        self.program = None
        self._initialize()
    
    def _is_problematic_windows_device(self, device, platform) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºWindowsä¸Šå¯èƒ½æœ‰é—®é¢˜çš„è®¾å¤‡"""
        try:
            device_name = device.name.lower()
            vendor_name = getattr(device, 'vendor', '').lower()
            platform_name = platform.name.lower()
            
            # Intelé›†æ˜¾çš„OpenCLé©±åŠ¨åœ¨Windowsä¸Šç»å¸¸æœ‰é—®é¢˜
            intel_keywords = ['intel', 'hd graphics', 'iris', 'uhd graphics']
            if any(keyword in device_name or keyword in vendor_name for keyword in intel_keywords):
                debug(f"    æ£€æµ‹åˆ°Intelé›†æ˜¾è®¾å¤‡: {device.name}", "GPU")
                return True
            
            # æŸäº›è€æ—§çš„OpenCLå®ç°
            if 'microsoft' in platform_name or 'basic render driver' in device_name:
                debug(f"    æ£€æµ‹åˆ°MicrosoftåŸºç¡€æ¸²æŸ“é©±åŠ¨: {device.name}", "GPU")
                return True
            
            # å†…å­˜è¿‡å°çš„è®¾å¤‡ï¼ˆé€šå¸¸æ˜¯é›†æ˜¾ï¼‰
            memory_mb = device.global_mem_size // (1024 * 1024)
            if memory_mb < 512:  # å°äº512MBçš„è®¾å¤‡é€šå¸¸æ˜¯é›†æ˜¾
                debug(f"    è®¾å¤‡å†…å­˜è¿‡å°({memory_mb}MB)ï¼Œå¯èƒ½æ˜¯é›†æ˜¾", "GPU")
                return True
                
            return False
            
        except Exception as e:
            warning(f"    æ— æ³•æ£€æŸ¥è®¾å¤‡å…¼å®¹æ€§: {e}", "GPU")
            return True  # ä¿å®ˆç­–ç•¥ï¼šæ— æ³•æ£€æŸ¥çš„è®¾å¤‡è®¤ä¸ºæœ‰é—®é¢˜
    
    def _initialize(self):
        """åˆå§‹åŒ–OpenCLç¯å¢ƒ"""
        if not OPENCL_AVAILABLE:
            debug("PyOpenCLæœªå®‰è£…ï¼Œè·³è¿‡OpenCLå¼•æ“åˆå§‹åŒ–", "GPU")
            return
        
        try:
            info("å¼€å§‹åˆå§‹åŒ–OpenCLç¯æ“", "GPU")
            
            # å¯»æ‰¾æœ€ä½³GPUè®¾å¤‡
            platforms = cl.get_platforms()
            info(f"å‘ç°{len(platforms)}ä¸ªOpenCLå¹³å°", "GPU")
            
            best_device = None
            best_compute_units = 0
            best_memory_mb = 0
            
            for i, platform in enumerate(platforms):
                debug(f"å¹³å°[{i}]: {platform.name} ({platform.vendor})", "GPU")
                
                try:
                    devices = platform.get_devices()
                    for j, device in enumerate(devices):
                        debug(f"  è®¾å¤‡[{j}]: {device.name} ({device.type})", "GPU")
                        
                        # åªè€ƒè™‘GPUè®¾å¤‡
                        if not (device.type & cl.device_type.GPU):
                            debug(f"    è·³è¿‡éGPUè®¾å¤‡", "GPU")
                            continue
                        
                        # è·å–è®¾å¤‡ä¿¡æ¯
                        compute_units = device.max_compute_units
                        memory_mb = device.global_mem_size // (1024 * 1024)
                        
                        debug(f"    è®¡ç®—å•å…ƒ: {compute_units}, æ˜¾å­˜: {memory_mb}MB", "GPU")
                        
                        # Windowsç‰¹å®šæ£€æŸ¥ï¼šè¿‡æ»¤å¯èƒ½æœ‰é—®é¢˜çš„è®¾å¤‡
                        import platform as sys_platform
                        if sys_platform.system() == 'Windows':
                            if self._is_problematic_windows_device(device, platform):
                                warning(f"    è·³è¿‡å¯èƒ½æœ‰é—®é¢˜çš„Windowsè®¾å¤‡: {device.name}", "GPU")
                                continue
                        
                        # å†…å­˜æ£€æŸ¥ï¼šè‡³å°‘éœ€è¦256MB
                        if memory_mb < 256:
                            warning(f"    è®¾å¤‡å†…å­˜ä¸è¶³({memory_mb}MB < 256MB)ï¼Œè·³è¿‡", "GPU")
                            continue
                        
                        # é€‰æ‹©æœ€ä½³è®¾å¤‡ï¼šä¼˜å…ˆè€ƒè™‘è®¡ç®—å•å…ƒï¼Œå…¶æ¬¡å†…å­˜
                        is_better = (compute_units > best_compute_units or 
                                    (compute_units == best_compute_units and memory_mb > best_memory_mb))
                        
                        if is_better:
                            best_device = device
                            best_compute_units = compute_units
                            best_memory_mb = memory_mb
                            debug(f"    é€‰ä¸ºæœ€ä½³è®¾å¤‡å€™é€‰", "GPU")
                            
                except cl.Error as e:
                    warning(f"  æ— æ³•è·å–å¹³å°{i}çš„è®¾å¤‡ä¿¡æ¯: {e}", "GPU")
                    continue
            
            if best_device:
                info(f"é€‰æ‹©OpenCLè®¾å¤‡: {best_device.name} ({best_compute_units}CU, {best_memory_mb}MB)", "GPU")
                
                # åˆ›å»ºä¸Šä¸‹æ–‡å’Œé˜Ÿåˆ—
                self.device = best_device
                self.context = cl.Context([best_device])
                self.queue = cl.CommandQueue(self.context)
                
                # æ„å»ºå†…æ ¸
                self._build_kernels()
                
                if self.program is not None:
                    info("OpenCLå¼•æ“åˆå§‹åŒ–æˆåŠŸ", "GPU")
                else:
                    error("OpenCLå†…æ ¸ç¼–è¯‘å¤±è´¥ï¼Œå¼•æ“ä¸å¯ç”¨", "GPU")
            else:
                warning("æœªæ‰¾åˆ°åˆé€‚çš„OpenCL GPUè®¾å¤‡", "GPU")
                
        except Exception as e:
            error(f"OpenCLåˆå§‹åŒ–å¤±è´¥: {e}", "GPU")
            import traceback
            debug(f"OpenCLåˆå§‹åŒ–å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}", "GPU")
    
    def _build_kernels(self):
        """ç¼–è¯‘OpenCLå†…æ ¸"""
        kernel_source = '''
        __kernel void density_inversion(__global const float* input,
                                       __global float* output,
                                       const float gamma,
                                       const float dmax,
                                       const float pivot,
                                       const int invert,
                                       const int size)
        {
            int i = get_global_id(0);
            if (i >= size) return;

            // é¿å…log(0)
            float safe_val = fmax(input[i], 1e-10f);

            // å¯†åº¦åç›¸è®¡ç®—ï¼ˆæ ¹æ® invert æ§åˆ¶æ­£è´Ÿå·ï¼‰
            float log_img = log10(safe_val);
            float original_density = invert ? -log_img : log_img;
            float adjusted_density = pivot + (original_density - pivot) * gamma - dmax;

            // è½¬å›çº¿æ€§ç©ºé—´
            output[i] = pow(10.0f, adjusted_density);
        }
        
        __kernel void curve_lut_apply(__global const float* input,
                                     __global float* output,
                                     __global const float* lut,
                                     const int image_size,
                                     const int lut_size)
        {
            int i = get_global_id(0);
            if (i >= image_size) return;
            
            // å½’ä¸€åŒ–åˆ°LUTç´¢å¼•èŒƒå›´
            float normalized = 1.0f - clamp(input[i] * 0.000152587890625f, 0.0f, 1.0f);
            float index_f = normalized * (lut_size - 1);
            int index = (int)index_f;
            
            // ç®€å•ç´¢å¼•ï¼ˆå¯ä»¥æ”¹ä¸ºæ’å€¼ï¼‰
            index = clamp(index, 0, lut_size - 1);
            output[i] = lut[index];
        }
        '''
        
        try:
            # å°è¯•ç¼–è¯‘å†…æ ¸
            debug("å¼€å§‹ç¼–è¯‘OpenCLå†…æ ¸", "GPU")
            info(f"ä¸ºè®¾å¤‡{self.device.name}ç¼–è¯‘OpenCLå†…æ ¸", "GPU")
            self.program = cl.Program(self.context, kernel_source).build()
            info("OpenCLå†…æ ¸ç¼–è¯‘æˆåŠŸ", "GPU")
            
            # éªŒè¯å†…æ ¸å‡½æ•°æ˜¯å¦å¯ç”¨
            try:
                density_kernel = self.program.density_inversion
                curve_kernel = self.program.curve_lut_apply
                debug("å†…æ ¸å‡½æ•°éªŒè¯æˆåŠŸ", "GPU")
            except AttributeError as e:
                error(f"å†…æ ¸å‡½æ•°éªŒè¯å¤±è´¥: {e}", "GPU")
                self.program = None
                
        except cl.CompileError as e:
            error(f"OpenCLå†…æ ¸ç¼–è¯‘é”™è¯¯: {e}", "GPU")
            debug(f"ç¼–è¯‘é”™è¯¯è¯¦æƒ…:\n{e}", "GPU")
            self.program = None
        except cl.Error as e:
            error(f"OpenCLç¼–è¯‘æ—¶å‘ç”Ÿé”™è¯¯: {e}", "GPU")
            self.program = None
        except Exception as e:
            error(f"OpenCLå†…æ ¸ç¼–è¯‘å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", "GPU")
            import traceback
            debug(f"ç¼–è¯‘å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}", "GPU")
            self.program = None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥OpenCLæ˜¯å¦å¯ç”¨"""
        return (OPENCL_AVAILABLE and 
                self.context is not None and 
                self.queue is not None and 
                self.program is not None)
    
    def get_device_info(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        if not self.is_available():
            return {"available": False}
        
        return {
            "available": True,
            "name": self.device.name,
            "type": "OpenCL",
            "compute_units": self.device.max_compute_units,
            "global_memory_mb": self.device.global_mem_size // 1024 // 1024,
            "max_work_group_size": self.device.max_work_group_size
        }
    
    def density_inversion_gpu(self, image: np.ndarray, gamma: float,
                             dmax: float, pivot: float, invert: bool = True) -> np.ndarray:
        """GPUåŠ é€Ÿçš„å¯†åº¦åç›¸"""
        if not self.is_available():
            raise RuntimeError("OpenCLä¸å¯ç”¨")

        debug(f"OpenCLå¯†åº¦åç›¸å¤„ç†: å›¾åƒ{image.shape}, gamma={gamma:.3f}, invert={invert}", "GPU")
        
        try:
            # å±•å¹³æ•°ç»„ä»¥ç®€åŒ–å¤„ç†
            original_shape = image.shape
            image_flat = image.flatten().astype(np.float32)
            output_flat = np.zeros_like(image_flat)
            
            debug(f"å¤„ç†{len(image_flat)}ä¸ªåƒç´ ", "GPU")
            
            # æ£€æŸ¥å†…å­˜å¤§å°
            memory_needed = len(image_flat) * 8  # input + output buffers
            device_memory = self.device.global_mem_size
            if memory_needed > device_memory * 0.8:  # ä¸ä½¿ç”¨è¶…è¿‡80%çš„æ˜¾å­˜
                warning(f"å†…å­˜éœ€æ±‚({memory_needed//1024//1024}MB)æ¥è¿‘è®¾å¤‡é™åˆ¶({device_memory//1024//1024}MB)", "GPU")
            
            # åˆ›å»ºOpenCLç¼“å†²åŒº
            mf = cl.mem_flags
            input_buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR, 
                                 hostbuf=image_flat)
            output_buf = cl.Buffer(self.context, mf.WRITE_ONLY, image_flat.nbytes)
            
            # æ‰§è¡Œå†…æ ¸
            global_size = (len(image_flat),)
            event = self.program.density_inversion(
                self.queue, global_size, None,
                input_buf, output_buf,
                np.float32(gamma), np.float32(dmax), np.float32(pivot),
                np.int32(1 if invert else 0),  # OpenCL ä½¿ç”¨ int è¡¨ç¤º bool
                np.int32(len(image_flat))
            )
            
            # ç­‰å¾…æ‰§è¡Œå®Œæˆ
            event.wait()
            
            # è¯»å–ç»“æœ
            cl.enqueue_copy(self.queue, output_flat, output_buf)
            
            debug("OpenCLå¯†åº¦åç›¸å¤„ç†å®Œæˆ", "GPU")
            
            # æ¢å¤åŸå§‹å½¢çŠ¶
            return output_flat.reshape(original_shape)
            
        except cl.MemoryError as e:
            error(f"OpenCLå†…å­˜ä¸è¶³: {e}", "GPU")
            raise RuntimeError(f"GPUå†…å­˜ä¸è¶³: {e}")
        except cl.Error as e:
            error(f"OpenCLæ‰§è¡Œé”™è¯¯: {e}", "GPU")
            raise RuntimeError(f"GPUæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            error(f"OpenCLå¯†åº¦åç›¸å¤„ç†å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", "GPU")
            import traceback
            debug(f"å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}", "GPU")
            raise
    
    def curve_processing_gpu(self, density_array: np.ndarray, 
                           lut: np.ndarray) -> np.ndarray:
        """GPUåŠ é€Ÿçš„æ›²çº¿å¤„ç†"""
        if not self.is_available():
            raise RuntimeError("OpenCLä¸å¯ç”¨")
        
        debug(f"OpenCLæ›²çº¿å¤„ç†: å›¾åƒ{density_array.shape}, LUTå¤§å°{len(lut)}", "GPU")
        
        try:
            # å±•å¹³æ•°ç»„
            original_shape = density_array.shape
            density_flat = density_array.flatten().astype(np.float32)
            output_flat = np.zeros_like(density_flat)
            lut_float = lut.astype(np.float32)
            
            debug(f"å¤„ç†{len(density_flat)}ä¸ªåƒç´ ï¼ŒLUT:{len(lut_float)}ä¸ªæ¡ç›®", "GPU")
            
            # æ£€æŸ¥å†…å­˜å¤§å°
            memory_needed = len(density_flat) * 8 + len(lut_float) * 4  # buffers
            device_memory = self.device.global_mem_size
            if memory_needed > device_memory * 0.8:
                warning(f"å†…å­˜éœ€æ±‚({memory_needed//1024//1024}MB)æ¥è¿‘è®¾å¤‡é™åˆ¶({device_memory//1024//1024}MB)", "GPU")
            
            # åˆ›å»ºOpenCLç¼“å†²åŒº
            mf = cl.mem_flags
            input_buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR, 
                                 hostbuf=density_flat)
            output_buf = cl.Buffer(self.context, mf.WRITE_ONLY, density_flat.nbytes)
            lut_buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR,
                               hostbuf=lut_float)
            
            # æ‰§è¡Œå†…æ ¸
            global_size = (len(density_flat),)
            event = self.program.curve_lut_apply(
                self.queue, global_size, None,
                input_buf, output_buf, lut_buf,
                np.int32(len(density_flat)), np.int32(len(lut_float))
            )
            
            # ç­‰å¾…æ‰§è¡Œå®Œæˆ
            event.wait()
            
            # è¯»å–ç»“æœ
            cl.enqueue_copy(self.queue, output_flat, output_buf)
            
            debug("OpenCLæ›²çº¿å¤„ç†å®Œæˆ", "GPU")
            
            # æ¢å¤åŸå§‹å½¢çŠ¶
            return output_flat.reshape(original_shape)
            
        except cl.MemoryError as e:
            error(f"OpenCLå†…å­˜ä¸è¶³: {e}", "GPU")
            raise RuntimeError(f"GPUå†…å­˜ä¸è¶³: {e}")
        except cl.Error as e:
            error(f"OpenCLæ‰§è¡Œé”™è¯¯: {e}", "GPU")
            raise RuntimeError(f"GPUæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            error(f"OpenCLæ›²çº¿å¤„ç†å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", "GPU")
            import traceback
            debug(f"å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}", "GPU")
            raise


class CUDAEngine(GPUComputeEngine):
    """CUDAè®¡ç®—å¼•æ“ - NVIDIA GPUä¸“ç”¨"""
    
    def __init__(self):
        self._available = CUDA_AVAILABLE
        if self._available:
            try:
                # æµ‹è¯•CUDAå¯ç”¨æ€§
                debug("å°è¯•åˆå§‹åŒ–CUDAå¼•æ“", "GPU")
                cp.cuda.Device(0).use()
                info("CUDAå¼•æ“åˆå§‹åŒ–æˆåŠŸ", "GPU")
            except Exception as e:
                warning(f"CUDAå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}", "GPU")
                self._available = False
        else:
            debug("CuPyæœªå®‰è£…ï¼Œè·³è¿‡CUDAå¼•æ“", "GPU")
    
    def is_available(self) -> bool:
        return self._available
    
    def get_device_info(self) -> Dict[str, Any]:
        if not self.is_available():
            return {"available": False}
        
        device = cp.cuda.Device()
        return {
            "available": True,
            "name": device.attributes["Name"],
            "type": "CUDA",
            "compute_capability": device.compute_capability,
            "memory_mb": device.mem_info[1] // 1024 // 1024
        }
    
    def density_inversion_gpu(self, image: np.ndarray, gamma: float,
                             dmax: float, pivot: float, invert: bool = True) -> np.ndarray:
        if not self.is_available():
            raise RuntimeError("CUDAä¸å¯ç”¨")

        # è½¬ç§»åˆ°GPU
        image_gpu = cp.asarray(image)

        # é¿å…log(0)
        safe_img = cp.maximum(image_gpu, 1e-10)

        # å¯†åº¦åç›¸è®¡ç®—ï¼ˆæ ¹æ® invert æ§åˆ¶æ­£è´Ÿå·ï¼‰
        log_img = cp.log10(safe_img)
        original_density = -log_img if invert else log_img
        adjusted_density = pivot + (original_density - pivot) * gamma - dmax
        result_gpu = cp.power(10.0, adjusted_density)

        # è½¬å›CPU
        return cp.asnumpy(result_gpu)
    
    def curve_processing_gpu(self, density_array: np.ndarray, 
                           lut: np.ndarray) -> np.ndarray:
        if not self.is_available():
            raise RuntimeError("CUDAä¸å¯ç”¨")
        
        # è½¬ç§»åˆ°GPU
        density_gpu = cp.asarray(density_array)
        lut_gpu = cp.asarray(lut)
        
        # è¿™é‡Œéœ€è¦å®ç°CUDAç‰ˆæœ¬çš„LUTæŸ¥è¡¨
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨CuPyçš„interp
        # å®é™…å®ç°éœ€è¦ä¼˜åŒ–çš„ç´¢å¼•æ“ä½œ
        
        # è½¬å›CPUï¼ˆå ä½å®ç°ï¼‰
        return cp.asnumpy(density_gpu)


class MetalEngine(GPUComputeEngine):
    """Metalè®¡ç®—å¼•æ“ - macOSåŸç”Ÿæœ€ä¼˜æ€§èƒ½"""
    
    def __init__(self):
        self.device = None
        self.command_queue = None
        self.library = None
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–Metalç¯å¢ƒ"""
        if not METAL_AVAILABLE:
            return
        
        try:
            # åˆ›å»ºMetalè®¾å¤‡å’Œå‘½ä»¤é˜Ÿåˆ—
            self.device = Metal.MTLCreateSystemDefaultDevice()
            if self.device:
                self.command_queue = self.device.newCommandQueue()
                self._create_compute_library()
        except Exception as e:
            error(f"Metalåˆå§‹åŒ–å¤±è´¥: {e}", "GPU")
    
    def _create_compute_library(self):
        """åˆ›å»ºMetalè®¡ç®—ç€è‰²å™¨åº“"""
        # Metalç€è‰²å™¨æºä»£ç 
        metal_source = '''
        #include <metal_stdlib>
        using namespace metal;
        
        // å¯†åº¦åç›¸è®¡ç®—ç€è‰²å™¨ï¼ˆé«˜ç²¾åº¦ç‰ˆæœ¬ï¼‰
        kernel void density_inversion(device const float* input [[buffer(0)]],
                                     device float* output [[buffer(1)]],
                                     constant float& gamma [[buffer(2)]],
                                     constant float& dmax [[buffer(3)]],
                                     constant float& pivot [[buffer(4)]],
                                     constant bool& invert [[buffer(5)]],
                                     uint index [[thread_position_in_grid]])
        {
            // ç¡®ä¿ä¸CPUç‰ˆæœ¬ç›¸åŒçš„ç²¾åº¦å¤„ç†
            float safe_val = max(input[index], 1e-10f);

            // å¯†åº¦åç›¸è®¡ç®— - æ ¹æ® invert æ§åˆ¶æ­£è´Ÿå·
            float log_img = log10(safe_val);
            float original_density = invert ? -log_img : log_img;
            float adjusted_density = pivot + (original_density - pivot) * gamma - dmax;

            // è½¬å›çº¿æ€§ç©ºé—´ - ä½¿ç”¨preciseæ ‡å¿—ç¡®ä¿ç²¾åº¦
            output[index] = precise::pow(10.0f, adjusted_density);
        }
        
        // LUTæŸ¥è¡¨ç€è‰²å™¨
        kernel void lut_apply(device const float* input [[buffer(0)]],
                             device float* output [[buffer(1)]],
                             device const float* lut [[buffer(2)]],
                             constant uint& lut_size [[buffer(3)]],
                             uint index [[thread_position_in_grid]])
        {
            // å½’ä¸€åŒ–åˆ°LUTç´¢å¼•èŒƒå›´
            float normalized = 1.0f - clamp(input[index] * 0.000152587890625f, 0.0f, 1.0f);
            float index_f = normalized * (lut_size - 1);
            uint lut_index = uint(index_f);
            
            // è¾¹ç•Œæ£€æŸ¥
            lut_index = min(lut_index, lut_size - 1);
            output[index] = lut[lut_index];
        }
        
        // çŸ©é˜µä¹˜æ³•ç€è‰²å™¨ï¼ˆç”¨äºè‰²å½©ç©ºé—´è½¬æ¢ï¼‰
        kernel void matrix_multiply_3x3(device const float* input [[buffer(0)]],
                                       device float* output [[buffer(1)]],
                                       device const float* matrix [[buffer(2)]],
                                       uint index [[thread_position_in_grid]])
        {
            uint pixel_index = index / 3;
            uint component = index % 3;
            uint base_index = pixel_index * 3;
            
            float result = 0.0f;
            for (uint i = 0; i < 3; i++) {
                result += matrix[component * 3 + i] * input[base_index + i];
            }
            output[index] = result;
        }
        '''
        
        try:
            # ç¼–è¯‘Metalç€è‰²å™¨
            library = self.device.newLibraryWithSource_options_error_(
                metal_source, None, None
            )
            if library[0]:
                self.library = library[0]
            else:
                error(f"Metalç€è‰²å™¨ç¼–è¯‘å¤±è´¥: {library[1]}", "GPU")
        except Exception as e:
            error(f"Metalç€è‰²å™¨åˆ›å»ºå¤±è´¥: {e}", "GPU")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥Metalæ˜¯å¦å¯ç”¨"""
        return (METAL_AVAILABLE and 
                self.device is not None and 
                self.command_queue is not None and 
                self.library is not None)
    
    def get_device_info(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        if not self.is_available():
            return {"available": False}
        
        return {
            "available": True,
            "name": self.device.name(),
            "type": "Metal",
            "unified_memory": self.device.hasUnifiedMemory(),
            "max_buffer_mb": self.device.maxBufferLength() // 1024 // 1024,
            "low_power": self.device.isLowPower()
        }
    
    def density_inversion_gpu(self, image: np.ndarray, gamma: float,
                             dmax: float, pivot: float, invert: bool = True) -> np.ndarray:
        """MetalåŠ é€Ÿçš„å¯†åº¦åç›¸"""
        if not self.is_available():
            raise RuntimeError("Metalä¸å¯ç”¨")
        
        # å±•å¹³æ•°ç»„
        original_shape = image.shape
        image_flat = image.flatten().astype(np.float32)
        output_flat = np.zeros_like(image_flat)
        
        # åˆ›å»ºMetalç¼“å†²åŒº
        input_buffer = self.device.newBufferWithBytes_length_options_(
            image_flat.tobytes(), 
            len(image_flat) * 4,  # float32 = 4 bytes
            Metal.MTLResourceStorageModeShared
        )
        
        output_buffer = self.device.newBufferWithLength_options_(
            len(image_flat) * 4,
            Metal.MTLResourceStorageModeShared
        )
        
        # å‚æ•°ç¼“å†²åŒº
        gamma_buffer = self.device.newBufferWithBytes_length_options_(
            np.array([gamma], dtype=np.float32).tobytes(), 4,
            Metal.MTLResourceStorageModeShared
        )
        
        dmax_buffer = self.device.newBufferWithBytes_length_options_(
            np.array([dmax], dtype=np.float32).tobytes(), 4,
            Metal.MTLResourceStorageModeShared
        )
        
        pivot_buffer = self.device.newBufferWithBytes_length_options_(
            np.array([pivot], dtype=np.float32).tobytes(), 4,
            Metal.MTLResourceStorageModeShared
        )

        # invert å‚æ•°ç¼“å†²åŒºï¼ˆMetal æ”¯æŒ bool ç±»å‹ï¼‰
        invert_buffer = self.device.newBufferWithBytes_length_options_(
            np.array([invert], dtype=np.bool_).tobytes(), 1,
            Metal.MTLResourceStorageModeShared
        )

        # åˆ›å»ºè®¡ç®—ç®¡çº¿
        function = self.library.newFunctionWithName_("density_inversion")
        pipeline_state = self.device.newComputePipelineStateWithFunction_error_(function, None)[0]
        
        # åˆ›å»ºå‘½ä»¤ç¼“å†²åŒºå’Œç¼–ç å™¨
        command_buffer = self.command_queue.commandBuffer()
        compute_encoder = command_buffer.computeCommandEncoder()
        
        # è®¾ç½®ç®¡çº¿å’Œç¼“å†²åŒº
        compute_encoder.setComputePipelineState_(pipeline_state)
        compute_encoder.setBuffer_offset_atIndex_(input_buffer, 0, 0)
        compute_encoder.setBuffer_offset_atIndex_(output_buffer, 0, 1)
        compute_encoder.setBuffer_offset_atIndex_(gamma_buffer, 0, 2)
        compute_encoder.setBuffer_offset_atIndex_(dmax_buffer, 0, 3)
        compute_encoder.setBuffer_offset_atIndex_(pivot_buffer, 0, 4)
        compute_encoder.setBuffer_offset_atIndex_(invert_buffer, 0, 5)
        
        # è®¡ç®—çº¿ç¨‹ç½‘æ ¼
        threads_per_threadgroup = Metal.MTLSize(256, 1, 1)
        threadgroups = Metal.MTLSize(
            (len(image_flat) + 255) // 256, 1, 1
        )
        
        compute_encoder.dispatchThreadgroups_threadsPerThreadgroup_(
            threadgroups, threads_per_threadgroup
        )
        
        compute_encoder.endEncoding()
        command_buffer.commit()
        command_buffer.waitUntilCompleted()
        
        # è¯»å–ç»“æœ - ä½¿ç”¨æ­£ç¡®çš„Metalç¼“å†²åŒºè®¿é—®æ–¹æ³•
        result_ptr = output_buffer.contents()
        # åˆ›å»ºnumpyæ•°ç»„ç›´æ¥æŒ‡å‘Metalç¼“å†²åŒºå†…å­˜
        result_array = np.frombuffer(
            result_ptr.as_buffer(len(image_flat) * 4), 
            dtype=np.float32
        ).copy()  # copyç¡®ä¿æ•°æ®ç‹¬ç«‹
        
        return result_array.reshape(original_shape)
    
    def curve_processing_gpu(self, density_array: np.ndarray, 
                           lut: np.ndarray) -> np.ndarray:
        """MetalåŠ é€Ÿçš„æ›²çº¿å¤„ç†"""
        if not self.is_available():
            raise RuntimeError("Metalä¸å¯ç”¨")
        
        # å±•å¹³æ•°ç»„
        original_shape = density_array.shape
        density_flat = density_array.flatten().astype(np.float32)
        output_flat = np.zeros_like(density_flat)
        lut_float = lut.astype(np.float32)
        
        # åˆ›å»ºMetalç¼“å†²åŒº
        input_buffer = self.device.newBufferWithBytes_length_options_(
            density_flat.tobytes(), 
            len(density_flat) * 4,
            Metal.MTLResourceStorageModeShared
        )
        
        output_buffer = self.device.newBufferWithLength_options_(
            len(density_flat) * 4,
            Metal.MTLResourceStorageModeShared
        )
        
        lut_buffer = self.device.newBufferWithBytes_length_options_(
            lut_float.tobytes(),
            len(lut_float) * 4,
            Metal.MTLResourceStorageModeShared
        )
        
        lut_size_buffer = self.device.newBufferWithBytes_length_options_(
            np.array([len(lut_float)], dtype=np.uint32).tobytes(), 4,
            Metal.MTLResourceStorageModeShared
        )
        
        # åˆ›å»ºè®¡ç®—ç®¡çº¿
        function = self.library.newFunctionWithName_("lut_apply")
        pipeline_state = self.device.newComputePipelineStateWithFunction_error_(function, None)[0]
        
        # åˆ›å»ºå‘½ä»¤ç¼“å†²åŒºå’Œç¼–ç å™¨
        command_buffer = self.command_queue.commandBuffer()
        compute_encoder = command_buffer.computeCommandEncoder()
        
        # è®¾ç½®ç®¡çº¿å’Œç¼“å†²åŒº
        compute_encoder.setComputePipelineState_(pipeline_state)
        compute_encoder.setBuffer_offset_atIndex_(input_buffer, 0, 0)
        compute_encoder.setBuffer_offset_atIndex_(output_buffer, 0, 1)
        compute_encoder.setBuffer_offset_atIndex_(lut_buffer, 0, 2)
        compute_encoder.setBuffer_offset_atIndex_(lut_size_buffer, 0, 3)
        
        # è®¡ç®—çº¿ç¨‹ç½‘æ ¼
        threads_per_threadgroup = Metal.MTLSize(256, 1, 1)
        threadgroups = Metal.MTLSize(
            (len(density_flat) + 255) // 256, 1, 1
        )
        
        compute_encoder.dispatchThreadgroups_threadsPerThreadgroup_(
            threadgroups, threads_per_threadgroup
        )
        
        compute_encoder.endEncoding()
        command_buffer.commit()
        command_buffer.waitUntilCompleted()
        
        # è¯»å–ç»“æœ - ä½¿ç”¨æ­£ç¡®çš„Metalç¼“å†²åŒºè®¿é—®æ–¹æ³•
        result_ptr = output_buffer.contents()
        # åˆ›å»ºnumpyæ•°ç»„ç›´æ¥æŒ‡å‘Metalç¼“å†²åŒºå†…å­˜
        result_array = np.frombuffer(
            result_ptr.as_buffer(len(density_flat) * 4), 
            dtype=np.float32
        ).copy()  # copyç¡®ä¿æ•°æ®ç‹¬ç«‹
        
        return result_array.reshape(original_shape)


class GPUAccelerator:
    """GPUåŠ é€Ÿå™¨ - ç»Ÿä¸€çš„GPUåŠ é€Ÿæ¥å£"""
    
    def __init__(self):
        self.engines = []
        self.active_engine = None
        self._initialize_engines()
    
    def _initialize_engines(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„è®¡ç®—å¼•æ“"""
        import os
        
        # æ£€æŸ¥æ˜¯å¦ç¦ç”¨GPUåŠ é€Ÿ
        if os.environ.get('DIVERE_DISABLE_GPU', '').lower() in ('1', 'true', 'yes'):
            info("æ£€æµ‹åˆ°DIVERE_DISABLE_GPUç¯å¢ƒå˜é‡ï¼Œç¦ç”¨GPUåŠ é€Ÿ", "GPU")
            return
        
        # æ ¹æ®å¹³å°è°ƒæ•´å¼•æ“ä¼˜å…ˆçº§
        if platform.system() == 'Windows':
            # Windows: CUDA > OpenCL > Metalï¼ˆMetalåœ¨Windowsä¸Šä¸å¯ç”¨ï¼‰
            engines_to_try = [
                ("CUDA", CUDAEngine),
                ("OpenCL", OpenCLEngine),
                ("Metal", MetalEngine),
            ]
            info("Windowså¹³å°ï¼šä¼˜å…ˆå°è¯•CUDAï¼Œç„¶åOpenCL", "GPU")
        elif platform.system() == 'Darwin':
            # macOS: Metal > OpenCL > CUDAï¼ˆä¼˜å…ˆåŸç”ŸåŠ é€Ÿï¼‰
            engines_to_try = [
                ("Metal", MetalEngine),
                ("OpenCL", OpenCLEngine), 
                ("CUDA", CUDAEngine),
            ]
            info("macOSå¹³å°ï¼šä¼˜å…ˆå°è¯•Metalï¼Œç„¶åOpenCL", "GPU")
        else:
            # Linuxç­‰: OpenCL > CUDA > Metal
            engines_to_try = [
                ("OpenCL", OpenCLEngine),
                ("CUDA", CUDAEngine),
                ("Metal", MetalEngine),
            ]
            info("Linuxå¹³å°ï¼šä¼˜å…ˆå°è¯•OpenCLï¼Œç„¶åCUDA", "GPU")
        
        info("å¼€å§‹åˆå§‹åŒ–GPUå¼•æ“", "GPU")
        
        for name, engine_class in engines_to_try:
            try:
                debug(f"å°è¯•åˆå§‹åŒ–{name}å¼•æ“", "GPU")
                engine = engine_class()
                if engine.is_available():
                    self.engines.append((name, engine))
                    if self.active_engine is None:
                        self.active_engine = engine
                        info(f"ğŸš€ ä½¿ç”¨GPUå¼•æ“: {name}", "GPU")
                        # è·å–è®¾å¤‡ä¿¡æ¯
                        device_info = engine.get_device_info()
                        debug(f"è®¾å¤‡ä¿¡æ¯: {device_info}", "GPU")
                else:
                    debug(f"{name}å¼•æ“ä¸å¯ç”¨", "GPU")
            except Exception as e:
                warning(f"âš ï¸  {name}å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}", "GPU")
                debug(f"{name}å¼•æ“åˆå§‹åŒ–å¼‚å¸¸è¯¦æƒ…: {e}", "GPU")
        
        if not self.engines:
            warning("æœªæ‰¾åˆ°å¯ç”¨çš„GPUå¼•æ“ï¼Œå°†ä½¿ç”¨CPUè®¡ç®—", "GPU")
        else:
            available_engines = [name for name, _ in self.engines]
            info(f"å¯ç”¨GPUå¼•æ“: {available_engines}", "GPU")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPUåŠ é€Ÿ"""
        return self.active_engine is not None
    
    def get_available_engines(self) -> List[str]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„å¼•æ“åˆ—è¡¨"""
        return [name for name, engine in self.engines]
    
    def get_device_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ¿€æ´»è®¾å¤‡çš„ä¿¡æ¯"""
        if not self.is_available():
            return {"available": False, "fallback": "CPU"}
        
        info = self.active_engine.get_device_info()
        info["engines_available"] = self.get_available_engines()
        return info
    
    def set_active_engine(self, engine_name: str) -> bool:
        """åˆ‡æ¢æ¿€æ´»çš„è®¡ç®—å¼•æ“"""
        for name, engine in self.engines:
            if name == engine_name:
                self.active_engine = engine
                info(f"ğŸ”„ åˆ‡æ¢åˆ°GPUå¼•æ“: {engine_name}", "GPU")
                return True
        return False
    
    def density_inversion_accelerated(self, image: np.ndarray, gamma: float,
                                     dmax: float, pivot: float, invert: bool = True) -> np.ndarray:
        """GPUåŠ é€Ÿçš„å¯†åº¦åç›¸ï¼Œè‡ªåŠ¨å›é€€åˆ°CPU"""
        if not self.is_available():
            debug("æ²¡æœ‰å¯ç”¨çš„GPUå¼•æ“ï¼Œä½¿ç”¨CPUå¤„ç†å¯†åº¦åç›¸", "GPU")
            return self._density_inversion_cpu(image, gamma, dmax, pivot, invert)

        try:
            debug(f"ä½¿ç”¨{type(self.active_engine).__name__}å¤„ç†å¯†åº¦åç›¸", "GPU")
            result = self.active_engine.density_inversion_gpu(image, gamma, dmax, pivot, invert)
            debug("GPUå¯†åº¦åç›¸å¤„ç†æˆåŠŸ", "GPU")
            return result
        except Exception as e:
            error(f"GPUåŠ é€Ÿå¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}", "GPU")
            debug(f"GPUå¤±è´¥è¯¦æƒ…: {e}", "GPU")
            return self._density_inversion_cpu(image, gamma, dmax, pivot, invert)
    
    def curve_processing_accelerated(self, density_array: np.ndarray, 
                                   lut: np.ndarray) -> np.ndarray:
        """GPUåŠ é€Ÿçš„æ›²çº¿å¤„ç†ï¼Œè‡ªåŠ¨å›é€€åˆ°CPU"""
        if not self.is_available():
            debug("æ²¡æœ‰å¯ç”¨çš„GPUå¼•æ“ï¼Œä½¿ç”¨CPUå¤„ç†æ›²çº¿", "GPU")
            return self._curve_processing_cpu(density_array, lut)
        
        try:
            debug(f"ä½¿ç”¨{type(self.active_engine).__name__}å¤„ç†æ›²çº¿", "GPU")
            result = self.active_engine.curve_processing_gpu(density_array, lut)
            debug("GPUæ›²çº¿å¤„ç†æˆåŠŸ", "GPU")
            return result
        except Exception as e:
            error(f"GPUåŠ é€Ÿå¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}", "GPU")
            debug(f"GPUå¤±è´¥è¯¦æƒ…: {e}", "GPU")
            return self._curve_processing_cpu(density_array, lut)
    
    def _density_inversion_cpu(self, image: np.ndarray, gamma: float,
                              dmax: float, pivot: float, invert: bool = True) -> np.ndarray:
        """CPUç‰ˆæœ¬çš„å¯†åº¦åç›¸ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        debug(f"CPUå¯†åº¦åç›¸å¤„ç†: å›¾åƒ{image.shape}, gamma={gamma:.3f}, invert={invert}", "GPU")
        safe_img = np.maximum(image, 1e-10)
        log_img = np.log10(safe_img)
        original_density = -log_img if invert else log_img
        adjusted_density = pivot + (original_density - pivot) * gamma - dmax
        result = np.power(10.0, adjusted_density)
        debug("CPUå¯†åº¦åç›¸å¤„ç†å®Œæˆ", "GPU")
        return result
    
    def _curve_processing_cpu(self, density_array: np.ndarray, 
                             lut: np.ndarray) -> np.ndarray:
        """CPUç‰ˆæœ¬çš„æ›²çº¿å¤„ç†ï¼ˆå›é€€æ–¹æ¡ˆï¼‰- ä½¿ç”¨é«˜ç²¾åº¦æ’å€¼"""
        debug(f"CPUæ›²çº¿å¤„ç†: å›¾åƒ{density_array.shape}, LUTå¤§å°{len(lut)}", "GPU")
        
        # é«˜ç²¾åº¦çº¿æ€§æ’å€¼å®ç°ï¼Œé¿å…ç®€å•ç´¢å¼•é€ æˆçš„é‡åŒ–è¯¯å·®
        inv_range = 1.0 / 6.5536  # LOG65536çš„å€’æ•°
        normalized = 1.0 - np.clip(density_array * inv_range, 0.0, 1.0)
        
        # ä½¿ç”¨NumPyçš„é«˜ç²¾åº¦æ’å€¼è€Œä¸æ˜¯ç®€å•ç´¢å¼•
        lut_indices = np.linspace(0.0, 1.0, len(lut), dtype=np.float64)
        result = np.interp(normalized.flatten(), lut_indices, lut).astype(density_array.dtype)
        
        debug("CPUæ›²çº¿å¤„ç†å®Œæˆ", "GPU")
        return result.reshape(density_array.shape)


# å…¨å±€GPUåŠ é€Ÿå™¨å®ä¾‹
_gpu_accelerator = None

def get_gpu_accelerator() -> GPUAccelerator:
    """è·å–å…¨å±€GPUåŠ é€Ÿå™¨å®ä¾‹"""
    global _gpu_accelerator
    if _gpu_accelerator is None:
        _gpu_accelerator = GPUAccelerator()
    return _gpu_accelerator
